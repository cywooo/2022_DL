# -*- coding: utf-8 -*-
"""h1_2_310513045.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HUF9zE7A6BJ__0jG6UyRxcASAbcpFRGr
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import glob
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import torch.optim as optim
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from sklearn.model_selection import train_test_split
device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # 判斷是否有GPU資源可用
print(device)

#%% Dataset路徑抓取
data_x, data_y, test_x, test_y = [], [], [], []

#自定義好label所對應到的資料夾
labels = ['Afghan_hound', 'Airedale', 'basenji', 'Bernese_mountain_dog', 'Irish_wolfhound', 'Leonberg', 'Scottish_deerhound', 'Tibetan_terrier']

#自行抓取資料所在的路徑
for i in range(len(labels)):
    temp_train = glob.glob(os.path.join('/content/drive/MyDrive/DL_HW1/stanford_dogs_dataset/train',labels[i],"*.jpg"))
    temp_test = glob.glob(os.path.join('/content/drive/MyDrive/DL_HW1/stanford_dogs_dataset/test',labels[i],"*.jpg"))
    
    data_x.extend(temp_train)
    data_y.extend([i for j in range(len(temp_train))])
    test_x.extend(temp_test)
    test_y.extend([i for j in range(len(temp_test))])

# 把train data分成train跟validation
train_x, val_x, train_y, val_y = train_test_split(data_x, data_y)

#%% 自定義資料集設定
#透過transform對資料做Data Augmentation
traintransform = transforms.Compose([
    transforms.Resize([256,256]),
    transforms.RandomCrop(224),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(20),
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))])

testtransform = transforms.Compose([
    transforms.Resize([224,224]),
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))])

#自定義好輸入要使用的資料形式
#另外可以最下面transform那邊看到image是可以直接丟進transform中做轉換的
class MyDataset(Dataset):
    def __init__(self, Xnp, Ynp, transform):   
        self.Xnp = Xnp
        self.Ynp = Ynp
        self.transform = transform

    def __len__(self):
        return len(self.Ynp)
    
    def __getitem__(self, index):
        x = self.read_img(index)
        y = self.Ynp[index]
        return x, y
    
    def read_img(self, index):
        img = Image.open(self.Xnp[index])
        img = self.transform(img)
        return img

trainset = MyDataset(train_x, train_y, traintransform)    
valset = MyDataset(val_x, val_y, testtransform)    
testset = MyDataset(test_x, test_y, testtransform)

trainloader = DataLoader(trainset, batch_size=30, shuffle=True, num_workers=0)
valloader = DataLoader(valset, batch_size=30, shuffle=True, num_workers=0)
testloader = DataLoader(testset, batch_size=len(train_y), shuffle=False, num_workers=0)

#%% 自定義模型
"""
class Cnn(nn.Module):
  def __init__(self):
      super(Cnn,self).__init__()
      self.conv1 = nn.Conv2d(3,6,3)
      self.pool = nn.MaxPool2d(2)
      self.conv2 = nn.Conv2d(6,10,3)
      self.conv3 = nn.Conv2d(10,16,3)   
      self.fc1 = nn.Linear(16*26*26,676)
      self.fc2 = nn.Linear(676,8)
      self.dropout = nn.Dropout()
  def forward(self, x):
    x = self.pool(F.relu(self.conv1(x)))
    x = self.pool(F.relu(self.conv2(x)))
    x = self.pool(F.relu(self.conv3(x)))
    x = torch.flatten(x,start_dim=1)
    x = F.relu(self.dropout(self.fc1(x)))
    x = self.fc2(x)
    return x

net = Cnn()
"""

class Cnn(nn.Module):
  def __init__(self, num_classes):
        super(Cnn, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=11, padding=2, stride=4)
        self.conv2 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=5, padding=2)
        self.conv3 = nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1)
        self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)

        self.fc1 = nn.Linear(in_features=256*6*6, out_features=4096)
        self.fc2 = nn.Linear(in_features=4096, out_features=1024)
        self.fc3 = nn.Linear(in_features=1024, out_features=num_classes)

  def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, kernel_size=3, stride=2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, kernel_size=3, stride=2)
        x = F.relu(self.conv3(x))
        x = F.relu(self.conv4(x))
        x = F.relu(self.conv5(x))
        x = F.max_pool2d(x, kernel_size=3, stride=2)
        # x = x.view(x.size(0), -1)
        x = torch.flatten(x, start_dim=1)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, p=0.5)
        x = F.relu(self.fc2(x))
        x = F.dropout(x, p=0.5)
        x = self.fc3(x)
        return x

net = Cnn(len(labels))

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters(), lr=0.0001, eps=1e-5)

#%% 模型訓練
epoch = 100

loss_train = np.zeros((epoch))
loss_val = np.zeros((epoch))
accuracy_train = np.zeros((epoch))
accuracy_val = np.zeros((epoch))
net = net.to(device)

for epoch in range(epoch):

  print('Now is epoch no.', epoch+1)
  net.train()
  
  for i,(inputs,target) in enumerate(trainloader,0):
    optimizer.zero_grad()
    inputs, target = inputs.to(device).float(), target.to(device)
    outputs = net(inputs)
    loss = criterion(outputs, target)
    loss_train[epoch] += loss.item()
    _, predicted = torch.max(outputs.data,1)
    accuracy_train[epoch] += (predicted == target).sum().item()
    loss.backward()
    optimizer.step()
  
    
  net.eval()
  with torch.no_grad():
    for i,(inputs,target) in enumerate(valloader):
      inputs, target = inputs.to(device).float(), target.to(device)
      outputs = net(inputs)
      loss = criterion(outputs, target)
      loss_val[epoch] += loss.item()
      _, predicted = torch.max(outputs.data,1)
      accuracy_val[epoch] += (predicted == target).sum().item()
  
  print('The loss of training in this epoch is', loss_train[epoch]/len(train_y))
  print('The loss of validation in this epoch is', loss_val[epoch]/len(val_y))
  print('----------------------------------------------------------------------------------')
  print('The acc of training in this epoch is', 100*(accuracy_train[epoch]/len(train_y)), '%')
  print('The acc of validation in this epoch is', 100*(accuracy_val[epoch]/len(val_y)), '%')


plt.figure(1)
plt.plot(np.arange(epoch+1),loss_train/len(train_y),np.arange(epoch+1),loss_val/len(val_y))
plt.xlabel('epoch')
plt.ylabel('loss')
plt.title('learning curve')
plt.legend(['train','validation'])

plt.figure(2)
plt.plot(np.arange(epoch+1),100*accuracy_train/len(train_y),np.arange(epoch+1),100*accuracy_val/len(val_y))
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.title('accuracy curve')
plt.legend(['train','validation'])

#%% Testing
acc_test = 0
loss_test = 0
net.eval()
with torch.no_grad():
  for i,(inputs,target) in enumerate(testloader):
    inputs, target = inputs.to(device).float(), target.to(device)
    outputs = net(inputs)
    loss = criterion(outputs, target)
    loss_test += loss.item()
    _, predicted = torch.max(outputs.data,1)
    acc_test += (predicted == target).sum().item()

print('The loss of testing in this epoch is', loss_test/len(test_y))
print('The acc of testing in this epoch is', 100*(acc_test/len(test_y)), '%')
